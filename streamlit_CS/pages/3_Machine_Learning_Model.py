import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
import plotly.express as px
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import matplotlib.patches as mpatches
import seaborn as sns
from pathlib import Path
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.tree import plot_tree
from filters import apply_pokemon_filters
from filters import TYPE_COLORS

# ───────────────────────────
# PAGE CONFIG
# ───────────────────────────
st.set_page_config(
    page_title="Machine Learning Model",
    page_icon="⚙️",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ───────────────────────────
# LOAD DATA
# ───────────────────────────
DATA_PATH = Path(__file__).parent.parent / "data" / "pokemon_dataset.csv"
df = pd.read_csv(DATA_PATH)
df_filtered = apply_pokemon_filters(df)

# ───────────────────────────
# PAGE HEADER
# ───────────────────────────
st.title("⚙️ Machine Learning Model")
st.caption(f"Current filters: {len(df_filtered)} Pokémon selected.")
st.markdown("""
This page uses a **Random Forest** machine learning model to predict a Pokémon’s **primary type** based on its six base stats.  
The model is evaluated using **Stratified K-Fold Cross-Validation**, and its results are visualized through a **confusion matrix** and an overall **accuracy score**.
The importance of each feature is also calculated and displayed on the right side of the page.
The model’s hyperparameters can be adjusted on the left of the page to see how tuning affects performance.
""")
st.divider()

# Guard: need data and at least 2 classes
if df_filtered.empty:
    st.warning("No Pokémon available for the selected filters. Adjust filters in the sidebar.")
    st.stop()

if df_filtered["primary_type"].nunique() < 2:
    st.warning("Not enough primary type classes in the filtered data to train a classifier.")
    st.stop()

# ───────────────────────────
# FEATURES AND TARGET
# ───────────────────────────
# Define the columns that will be used in the model
STAT_COLS = ["hp", "attack", "defense", "special-attack", "special-defense", "speed"]
df_ml = df_filtered.dropna(subset=STAT_COLS + ["primary_type"]).copy()

# Extra guards: after dropna + filters we still need data and ≥ 2 classes
if df_ml.empty:
    st.warning("Not enough Pokémon with complete stat data after filtering to train a model.")
    st.stop()

if df_ml["primary_type"].nunique() < 2:
    st.warning("Not enough different primary types in the filtered data to train a classifier.")
    st.stop()

X = df_ml[STAT_COLS].values
y = df_ml["primary_type"].values

label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)
class_names = list(label_encoder.classes_)

# For K-fold upper bound, we need class counts from the filtered data
class_counts = df_ml["primary_type"].value_counts()
min_class_count = int(class_counts.min())  # smallest class size

# Base K on the rarest class, capped at 10
max_k_allowed = min(10, min_class_count)

# Make sure K is at least 2 so StratifiedKFold works
if max_k_allowed < 2:
    max_k_allowed = 2

# ───────────────────────────
# ROW 1 – controls (col 1) + confusion matrix + feature importances (col 2)
# ───────────────────────────
col1_r1, col2_r1 = st.columns([1, 2])

# Random Forest controls
with col1_r1:
    st.subheader("Random Forest Settings")

    # Slider for determining k, maxed out at 2 if previous settings limit it too much, default value of 5
    if max_k_allowed == 2:
        k_folds = 2
        st.caption(
            "Using K = 2 (minimum allowed) because at least one primary type is very rare "
            "with the current filters."
        )
    else:
        k_folds = st.slider(
            "Number of Folds (K)",
            min_value=2,
            max_value=max_k_allowed,
            value=min(5, max_k_allowed),
            help=(
                "How many chunks (folds) the data is split into for cross-validation. "
                "Higher K means more training runs but a more stable estimate of accuracy."
            ),
        )

    # Slider for determining the number of trees, default value of 200
    n_estimators = st.slider(
        "Number of Trees (n_estimators)",
        10,
        1000,
        200,
        step=10,
        help="How many decision trees are in the forest. More trees usually improve stability, "
             "but also take longer to train."
    )

    # Slider for determining the maximum tree depth, default value of 8
    max_depth = st.slider(
        "Max Tree Depth",
        1,
        20,
        8,
        help="How many splits each tree is allowed to make from top to bottom. "
             "Shallower trees are simpler and may generalize better."
    )

    # Checkbox to overide the previous slider so that there is no max tree depth
    use_max_depth_none = st.checkbox(
        "Disable Max Tree Depth",
        value=False,
        help="If checked, trees can grow as deep as they want until other stopping rules are hit."
    )
    if use_max_depth_none:
        rf_max_depth = None
    else:
        rf_max_depth = max_depth

    # Slider for determining the minimum number of samples required to split a node, default value of 2
    min_samples_split = st.slider(
        "Min Samples Split",
        2,
        20,
        2,
        help="The minimum number of data points required in a node before it can be split into children."
    )

    # Slider for determining the minimum number of data points in a leaf node, default value of 1
    min_samples_leaf = st.slider(
        "Min Samples Leaf",
        1,
        10,
        1,
        help="The minimum number of data points that must end up in a leaf node "
             "(the final box at the bottom of a tree)."
    )

    # Selectbox to determine which criteria to use for calculating node purity
    criterion = st.selectbox(
        "Split Criterion",
        ["gini", "entropy"],
        index=0,
        help="The formula used to measure how 'mixed' a node is. "
             "Both try to create purer groups of types after each split."
    )

    # Selectbox to determine how many stats are considered at each split, default value of sqrt(6)
    max_features_choice = st.selectbox(
        "Max Features per Split",
        ["sqrt", "log2", "None"],
        index=0,
        help="How many stats are considered at each split. 'sqrt' and 'log2' introduce randomness. "
             "'None' means all features are always used."
    )
    if max_features_choice == "None":
        rf_max_features = None
    else:
        rf_max_features = max_features_choice

    # Checkbox to toggle bootstrapping, default value of True
    bootstrap = st.checkbox(
        "Use Bootstrap Samples",
        value=True,
        help="If checked, each tree is trained on a random sample (with replacement) of the data. "
    )

# ───────────────────────────
# TRAIN MODEL WITH STRATIFIED K-FOLD (FOR METRICS ONLY)
# ───────────────────────────
kf = StratifiedKFold(n_splits=k_folds, shuffle=True)

fold_accuracies = []
cm_total = np.zeros((len(class_names), len(class_names)), dtype=int)

for train_idx, test_idx in kf.split(X, y_encoded):
    X_train, X_test = X[train_idx], X[test_idx]
    y_train, y_test = y_encoded[train_idx], y_encoded[test_idx]

    # This model is used ONLY inside the fold loop to compute
    # accuracy and build the confusion matrix on unseen data.
    cv_model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=rf_max_depth,
        min_samples_split=min_samples_split,
        min_samples_leaf=min_samples_leaf,
        criterion=criterion,
        max_features=rf_max_features,
        bootstrap=bootstrap,
        n_jobs=-1,
    )

    cv_model.fit(X_train, y_train)
    y_pred = cv_model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    fold_accuracies.append(acc)

    cm = confusion_matrix(y_test, y_pred, labels=range(len(class_names)))
    cm_total += cm

# Fit one model on the full data for interpretation (feature importances and example tree)
model_full = RandomForestClassifier(
    n_estimators=n_estimators,
    max_depth=rf_max_depth,
    min_samples_split=min_samples_split,
    min_samples_leaf=min_samples_leaf,
    criterion=criterion,
    max_features=rf_max_features,
    bootstrap=bootstrap,
    n_jobs=-1,
)
model_full.fit(X, y_encoded)

importances = model_full.feature_importances_
feat_imp = (
    pd.DataFrame({"feature": STAT_COLS, "importance": importances})
    .sort_values("importance", ascending=False)
)

mean_acc = float(np.mean(fold_accuracies))

with col2_r1:
    # Large text that displays the model accuracy
    st.markdown(
        f"<h2 style='text-align:center; margin-top: 0.5rem;'>"
        f"Model Accuracy: {mean_acc * 100:.2f}%"
        f"</h2>",
        unsafe_allow_html=True,
    )

    # Heatmap that shows the confusion matrix of the model
    cm_fig = px.imshow(
        cm_total,
        x=class_names,
        y=class_names,
        text_auto=True,
        aspect="auto",
        color_continuous_scale="Reds",
        labels=dict(color="Count", x="Predicted Primary Type", y="True Primary Type"),
    )

    cm_fig.update_layout(
        title="Confusion Matrix (Stratified K-Fold)",
        margin=dict(l=10, r=10, t=40, b=10),
    )

    st.plotly_chart(cm_fig, use_container_width=True)

    # Bar chart that displays feature importance
    fig_imp = px.bar(
        feat_imp,
        x="feature",
        y="importance",
        title="Relative Importance of Stats",
        text_auto=".2f",
    )

    fig_imp.update_layout(
        xaxis_title="Stat",
        yaxis_title="Importance",
        margin=dict(l=10, r=10, t=40, b=10),
        height=250
    )

    st.plotly_chart(fig_imp, use_container_width=True)

# Expanding window that displays per-classes metrics
with st.expander("Per-Type Performance Metrics", expanded=False):
    cm = cm_total  # shape: (n_classes, n_classes)
    total = cm.sum()

    # True positives are the diagonal
    tp = np.diag(cm)

    # False positives: column sum minus TP
    fp = cm.sum(axis=0) - tp

    # False negatives: row sum minus TP
    fn = cm.sum(axis=1) - tp

    # True negatives: everything else
    tn = total - tp - fp - fn

    # Per-class accuracy: (TP + TN) / total samples
    accuracy = (tp + tn) / total

    # Per-class precision: TP / (TP + FP)
    precision = np.divide(
        tp,
        tp + fp,
        out=np.full_like(tp, np.nan, dtype=float),
        where=(tp + fp) != 0,
    )

    # Per-class recall: TP / (TP + FN)
    recall = np.divide(
        tp,
        tp + fn,
        out=np.full_like(tp, np.nan, dtype=float),
        where=(tp + fn) != 0,
    )

    # Per-class F1: 2 * P * R / (P + R)
    f1 = np.divide(
        2 * precision * recall,
        precision + recall,
        out=np.full_like(precision, np.nan),
        where=(precision + recall) != 0,
    )

    metrics_df = pd.DataFrame(
        {
            "primary_type": class_names,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
        }
    )

    # Round for display
    metrics_df[["accuracy", "precision", "recall", "f1_score"]] = (
        metrics_df[["accuracy", "precision", "recall", "f1_score"]].round(3)
    )

    st.dataframe(metrics_df, use_container_width=True)

st.markdown("""
From the results above, we see that predicting a Pokémon’s primary type using only its base stats is challenging for a Random Forest model. 
The confusion matrix highlights that many types are frequently misclassified as others with similar stat profiles, resulting in a relatively low overall accuracy. 
The feature importance chart shows that certain stats tend to influence predictions more strongly than others, but not by a wide margin. 
These findings suggest that base stats alone do not uniquely differentiate most Pokémon types, and additional features not included in this model may be needed to build a more accurate classification model.
Despite the relatively low accuracy score of **~21%**, this model is still an improvement over random predictions. A random prediction with 18 categories would yield an accuracy of **~5.5%**.
""")

# ───────────────────────────
# ROW 2 – Decision Tree Visualization (simple filled tree at max depth=3)
# ───────────────────────────
from sklearn.tree import plot_tree

st.divider()
st.subheader("Example Decision Tree from the Random Forest (Max tree depth displayed is 3)")

# Extract the first tree from the full-data model used for interpretation
tree_clf = model_full.estimators_[0]

# Visualize only top part of the tree: max depth = 3
fig, ax = plt.subplots(figsize=(22, 12))

plot_tree(
    tree_clf,
    feature_names=STAT_COLS,
    class_names=class_names,
    filled=True,
    rounded=True,
    impurity=True,
    fontsize=10,
    max_depth=3,
    ax=ax,
)

plt.tight_layout()
st.pyplot(fig)
